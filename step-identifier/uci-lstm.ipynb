{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inspired on** https://machinelearningmastery.com/how-to-develop-rnn-models-for-human-activity-recognition-time-series-classification/\n",
    "\n",
    "> Using the raw dataset instead (https://archive.ics.uci.edu/ml/datasets/Smartphone-Based+Recognition+of+Human+Activities+and+Postural+Transitions).\n",
    "\n",
    "We'll be focusing on the WALKING activity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from functools import reduce\n",
    "\n",
    "data_location = '../datasets/uci-har-raw/'\n",
    "data_location_raw = data_location + 'RawData/'\n",
    "labels_of_interest = [1]\n",
    "\n",
    "def extract(file, begin, end):\n",
    "    partial_df = pd.read_csv(file, skipinitialspace=True, delim_whitespace=True, header=None)\n",
    "    partial_df.columns = ['x', 'y', 'z']\n",
    "    partial_df = partial_df.iloc[begin:end]\n",
    "\n",
    "    return partial_df\n",
    "\n",
    "def get_sensors_data(row):\n",
    "    \n",
    "    sensors = ['acc', 'gyro']\n",
    "    frames = list()\n",
    "\n",
    "    for sensor in sensors:\n",
    "        file = data_location_raw + sensor + '_exp' + \"{:02}\".format(row['experiment']) + '_user' + \"{:02}\".format(row['user']) + '.txt'\n",
    "        target = extract(file, row['begin'], row['end'] + 1)\n",
    "        target.columns = [f'{sensor}_x', f'{sensor}_y', f'{sensor}_z']\n",
    "        # Validation & segmentation purposes\n",
    "        target[f'{sensor}_user'] = row['user']\n",
    "        target[f'{sensor}_exp'] = row['experiment']\n",
    "        frames.append(target)\n",
    "\n",
    "    return frames[0].join(frames[1])\n",
    "\n",
    "def run_experiment():\n",
    "    \n",
    "    labels_of_interest = [1]\n",
    "\n",
    "    df_guide = pd.read_csv(data_location_raw + 'labels.txt', delim_whitespace=True, header=None)\n",
    "    df_guide.columns = ['experiment', 'user', 'label', 'begin', 'end']\n",
    "\n",
    "    df_target = df_guide[df_guide['label'].isin(labels_of_interest)]\n",
    "    \n",
    "    axis_df = pd.DataFrame()\n",
    "    \n",
    "    for index, row in df_target.iterrows():\n",
    "        axis_df = axis_df.append(get_sensors_data(row), ignore_index=True, sort=False)\n",
    "    \n",
    "    axis_df['label'] = labels_of_interest[0]\n",
    "    \n",
    "    return axis_df\n",
    "\n",
    "result = run_experiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = result.copy()\n",
    "\n",
    "df_raw.columns = [\"acx\", \"acy\", \"acz\", \"acu\", \"ace\", \"gyx\", \"gyy\", \"gyz\", \"gyu\", \"gye\", \"label\"]\n",
    "# Cheap tri-axial accelerometer normalization\n",
    "df_raw['sac'] = np.sqrt(np.power(df_raw['acx'], 2) + np.power(df_raw['acy'], 2) + np.power(df_raw['acz'], 2))\n",
    "# Cheap tri-axial gyroscope normalization\n",
    "df_raw['sgy'] = np.sqrt(np.power(df_raw['gyx'], 2) + np.power(df_raw['gyy'], 2) + np.power(df_raw['gyz'], 2))\n",
    "\n",
    "df_raw.drop([\"acx\", \"acy\", \"acz\", \"acu\", \"ace\", \"gyx\", \"gyy\", \"gyz\"], axis=1, inplace=True)\n",
    "df_raw.rename(columns = { 'gyu': 'user', 'gye': 'experiment' }, inplace=True)\n",
    "df_raw['seq'] = pd.Index(range(df_raw.count()[0]))\n",
    "df_raw.set_index(df_raw['seq'], drop=False)\n",
    "\n",
    "df_raw.plot.line('seq', ['sac', 'sgy'], alpha=0.5)\n",
    "df_raw.plot.scatter(x='sac', y='sgy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train / Test set (TODO: validation missing.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "def get_sets():\n",
    "    X_train = df_raw[df_raw['user'].isin(range(1,22))]\n",
    "    y_train = X_train['label']\n",
    "    X_train.drop(['seq', 'label', 'user', 'experiment'], axis=1, inplace=True)\n",
    "\n",
    "    X_test = df_raw[df_raw['user'].isin(range(22,31))]\n",
    "    y_test = X_test['label']\n",
    "    X_test.drop(['seq', 'label', 'user', 'experiment'], axis=1, inplace=True)\n",
    "\n",
    "    trainy = y_train.values\n",
    "    testy = y_test.values\n",
    "    # zero-offset class values\n",
    "    trainy = trainy - 1\n",
    "    testy = testy - 1\n",
    "\t# one hot encode y\n",
    "    trainy = to_categorical(trainy)\n",
    "    testy = to_categorical(testy)\n",
    "\n",
    "    X_train.info()\n",
    "\n",
    "    return X_train, trainy, X_test, testy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Windowing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: optimize this block.\n",
    "\n",
    "def windowed():\n",
    "\n",
    "    _HALF_SEC = 25 # for a 50hz capture\n",
    "\n",
    "    trainX, trainy, testX, testy = get_sets()\n",
    "\n",
    "    loaded_train = list()\n",
    "\n",
    "    df_train = pd.DataFrame(trainX, columns=['sac', 'sgy'])\n",
    "\n",
    "    sac_data = df_train.iloc[:,0].values\n",
    "    loaded_train.append(sac_data)\n",
    "    loaded_train_stack = dstack(loaded_train)\n",
    "\n",
    "    sgy_data = df_train.iloc[:,1].values\n",
    "    loaded_train.append(sgy_data)\n",
    "    loaded_train_stack = dstack(loaded_train)\n",
    "\n",
    "    trainX = loaded_train_stack\n",
    "\n",
    "    loaded_test = list()\n",
    "\n",
    "    df_test = pd.DataFrame(testX, columns=['sac', 'sgy'])\n",
    "\n",
    "    sac_data = df_test.iloc[:,0].values\n",
    "    loaded_test.append(sac_data)\n",
    "    loaded_test_stack = dstack(loaded_test)\n",
    "\n",
    "    sgy_data = df_test.iloc[:,1].values\n",
    "    loaded_test.append(sgy_data)\n",
    "    loaded_test_stack = dstack(loaded_test)\n",
    "\n",
    "    testX = loaded_test_stack\n",
    "    # data = trainX['sac'].rolling(50)\n",
    "    # print(data)\n",
    "    trainX = np.moveaxis(trainX, [1],[0])\n",
    "    testX = np.moveaxis(testX, [1],[0])\n",
    "    return trainX, trainy, testX, testy\n",
    "\n",
    "    # agg_array = np.array([0,0,0,0,0,0,0,0])\n",
    "    # for i in range(0,len(df_raw), _HALF_SEC):\n",
    "    #     window_measure = df_raw.iloc[i:i+4,7]\n",
    "    #     window_measure_gy = df_raw.iloc[i:i+4,8]\n",
    "    #     window_time = df_raw.iloc[i:i+4,6]\n",
    "    #     to_add = np.array(\n",
    "    #         [window_measure.mean(),\n",
    "    #         window_measure.max(),\n",
    "    #         window_measure.min(),\n",
    "    #         window_measure_gy.mean(),\n",
    "    #         window_measure_gy.max(),\n",
    "    #         window_measure_gy.min(),\n",
    "    #         window_time.min(),\n",
    "    #         window_time.max()])\n",
    "    #     agg_array = np.vstack((agg_array, to_add))\n",
    "    # agg_array = np.delete(agg_array, 0, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lstm model\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import dstack\n",
    "from pandas import read_csv\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.utils import to_categorical\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# [removed dataset loading code...]\n",
    "\n",
    "# fit and evaluate a model\n",
    "\n",
    "def evaluate_model(trainX, trainy, testX, testy):\n",
    "\tverbose, epochs, batch_size = 0, 15, 64\n",
    "\t\n",
    "\t# n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
    "\tn_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
    "\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(LSTM(100, input_shape=(n_timesteps,n_features), return_sequences=False))\n",
    "\tmodel.add(Dropout(0.5))\n",
    "\tmodel.add(Dense(100, activation='relu'))\n",
    "\tmodel.add(Dense(n_outputs, activation='softmax'))\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\t# fit network\n",
    "\tmodel.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "\t# evaluate model\n",
    "\t_, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n",
    "\treturn accuracy\n",
    "\n",
    "# summarize scores\n",
    "def summarize_results(scores):\n",
    "\tprint(scores)\n",
    "\tm, s = mean(scores), std(scores)\n",
    "\tprint('Accuracy: %.3f%% (+/-%.3f)' % (m, s))\n",
    "\n",
    "# run an experiment\n",
    "def run_experiment(repeats=10):\n",
    "\t# load data\n",
    "\t# trainX, trainy, testX, testy = load_dataset()\n",
    "\ttrainX, trainy, testX, testy = windowed()\n",
    "\n",
    "\t# repeat experiment\n",
    "\tscores = list()\n",
    "\tfor r in range(repeats):\n",
    "\t\tscore = evaluate_model(trainX, trainy, testX, testy)\n",
    "\t\tscore = score * 100.0\n",
    "\t\tprint('>#%d: %.3f' % (r+1, score))\n",
    "\t\tscores.append(score)\n",
    "\t# summarize results\n",
    "\tsummarize_results(scores)\n",
    "\n",
    "# run the experiment\n",
    "run_experiment()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
